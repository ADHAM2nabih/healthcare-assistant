import streamlit as st
from streamlit_chat import message
import pandas as pd
import numpy as np
import re
import nltk
import requests
import time
import joblib
import pickle
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences

# NLTK Downloads
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('punkt_tab')

# Set page config
st.set_page_config(
    page_title="Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø·Ø¨ÙŠ Ø§Ù„Ø°ÙƒÙŠ",
    page_icon="ğŸ¥",
    layout="wide"
)

# Custom CSS
st.markdown("""
<style>
    .stApp {
        background: linear-gradient(135deg, #f5f7fa, #e4e8f0);
        color: #333;
    }
    .stTextInput>div>div>input {
        color: #333;
        background-color: rgba(255, 255, 255, 0.8);
    }
    .stButton>button {
        background-color: #4a90e2;
        color: white;
        border: none;
        transition: 0.3s;
    }
    .stButton>button:hover {
        background-color: #3a7bc8;
    }
    .chat-container {
        background: rgba(255, 255, 255, 0.9);
        backdrop-filter: blur(10px);
        border-radius: 15px;
        padding: 20px;
        margin-bottom: 20px;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    .diagnosis-card {
        background: #ffffff;
        border-radius: 10px;
        padding: 15px;
        margin: 10px 0;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state
if 'generated' not in st.session_state:
    st.session_state.generated = []
if 'past' not in st.session_state:
    st.session_state.past = []
if 'diagnosis' not in st.session_state:
    st.session_state.diagnosis = None

# Load models
@st.cache_resource
def load_models():
    specialty_label_encoder = joblib.load('label_encoder.joblib')
    with open('tokenizer.pkl', 'rb') as handle:
        specialty_tokenizer = pickle.load(handle)
    specialty_model = load_model('lstm_model.h5')
    
    disease_label_encoder = joblib.load('label_encoder_machine.joblib')
    disease_model = joblib.load('mlp_pipeline_model.pkl')
    
    return (specialty_label_encoder, specialty_tokenizer, specialty_model, 
            disease_label_encoder, disease_model)

(specialty_le, specialty_tokenizer, specialty_model,
 disease_le, disease_model) = load_models()

# Text preprocessing
def preprocess_text(text):
    stop_words = set(stopwords.words('english'))
    lemmatizer = WordNetLemmatizer()
    
    text = re.sub(r'[^a-zA-Z\s]', '', text.lower()).strip()
    words = word_tokenize(text)
    words = [word for word in words if word.lower() not in stop_words]
    words = [lemmatizer.lemmatize(word) for word in words]
    return ' '.join(words)

# Prediction functions
def predict_medical_condition(text):
    processed_text = preprocess_text(text)
    
    # Specialty prediction
    sequence = specialty_tokenizer.texts_to_sequences([processed_text])
    padded_sequence = pad_sequences(sequence, maxlen=100)
    specialty_pred = specialty_model.predict(padded_sequence)
    specialty_class = specialty_le.inverse_transform([np.argmax(specialty_pred)])[0]
    specialty_conf = np.max(specialty_pred)
    
    # Disease prediction
    disease_pred = disease_model.predict([processed_text])
    disease_class = disease_le.inverse_transform(disease_pred)[0]
    disease_conf = np.max(disease_model.predict_proba([processed_text]))
    
    return {
        'specialty': (specialty_class, specialty_conf),
        'disease': (disease_class, disease_conf)
    }

# Bot response generator with medical restrictions (English instructions)
def get_medical_response(user_input, diagnosis):
    medical_prompt = f"""
    You are an AI medical assistant. Based on these symptoms in Arabic:
    "{user_input}"
    
    The analysis suggests:
    - Medical specialty: {diagnosis['specialty'][0]} (confidence: {diagnosis['specialty'][1]*100:.1f}%)
    - Likely condition: {diagnosis['disease'][0]} (confidence: {diagnosis['disease'][1]*100:.1f}%)
    
    Generate a professional response in Arabic with:
    1. Brief greeting
    2. Suggested medical specialty
    3. Potential condition in simple terms
    4. One general advice
    5. Reminder to see a doctor
    
    Requirements:
    - Respond in Arabic (Modern Standard or simple dialect)
    - Keep it very short (2-3 sentences max)
    - Only include medical information
    - Never suggest specific treatments
    - Always emphasize this is preliminary
    - Must include disclaimer to see a real doctor
    
    Example structure:
    "Ù…Ø±Ø­Ø¨Ø§Ù‹ØŒ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ ØªØ´ÙŠØ± Ø¥Ù„Ù‰ ØªØ®ØµØµ [Ø§Ù„ØªØ®ØµØµ]. Ù‚Ø¯ ØªÙƒÙˆÙ† Ø­Ø§Ù„Ø© [Ø§Ù„Ø­Ø§Ù„Ø©]. Ù†Ù†ØµØ­ Ø¨[Ù†ØµÙŠØ­Ø© Ø¹Ø§Ù…Ø©] Ù…Ø¹ Ø¶Ø±ÙˆØ±Ø© Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø·Ø¨ÙŠØ¨."
    """
    
    api_url = "https://openrouter.ai/api/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {st.secrets['OPENROUTER_API_KEY']}",
        "Content-Type": "application/json",
        "HTTP-Referer": "https://medical-chatbot.com",
        "X-Title": "Medical Assistant"
    }
    payload = {
        "model": "qwen/qwen-2.5-7b-instruct:free",
        "messages": [{"role": "user", "content": medical_prompt}],
        "temperature": 0.7,
        "max_tokens": 150
    }
    
    try:
        response = requests.post(api_url, headers=headers, json=payload)
        response.raise_for_status()
        data = response.json()
        bot_reply = data['choices'][0]['message']['content']
        return re.sub(r'[{}]', '', re.sub(r'\\boxed\s*', '', bot_reply)).strip()
    except Exception as e:
        return f"Ø¹Ø°Ø±Ù‹Ø§ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨Ùƒ. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚Ù‹Ø§."

# Main app
st.title("ğŸ¥ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø·Ø¨ÙŠ Ø§Ù„Ø°ÙƒÙŠ")
st.write("Ø£Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ! ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ ÙÙ‡Ù… Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ø§Ù„Ø·Ø¨ÙŠØ© ÙˆØªÙˆØ¬ÙŠÙ‡Ùƒ Ù„Ù„ØªØ®ØµØµ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨.")

# Chat container
with st.container():
    st.markdown('<div class="chat-container">', unsafe_allow_html=True)
    
    if st.session_state.generated:
        for i in range(len(st.session_state.generated)-1, -1, -1):
            message(st.session_state.generated[i], key=str(i), is_user=False)
            message(st.session_state.past[i], is_user=True, key=str(i) + '_user')
    
    if st.session_state.diagnosis:
        with st.expander("ğŸ” Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø·Ø¨ÙŠØ©", expanded=False):
            st.markdown('<div class="diagnosis-card">', unsafe_allow_html=True)
            st.subheader("Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„")
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Ø§Ù„ØªØ®ØµØµ Ø§Ù„Ø·Ø¨ÙŠ", 
                         st.session_state.diagnosis['specialty'][0],
                         f"Ø«Ù‚Ø©: {st.session_state.diagnosis['specialty'][1]*100:.1f}%")
            
            with col2:
                st.metric("Ø§Ù„Ù…Ø±Ø¶ Ø§Ù„Ù…Ø­ØªÙ…Ù„", 
                         st.session_state.diagnosis['disease'][0],
                         f"Ø«Ù‚Ø©: {st.session_state.diagnosis['disease'][1]*100:.1f}%")
            
            st.warning("âš ï¸ Ù…Ù„Ø§Ø­Ø¸Ø©: Ù‡Ø°Ù‡ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ø³ØªØ´Ø§Ø±ÙŠØ© ÙÙ‚Ø· ÙˆÙ„Ø§ ØªØºÙ†ÙŠ Ø¹Ù† Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø·Ø¨ÙŠØ¨")
            st.markdown('</div>', unsafe_allow_html=True)
    
    st.markdown('</div>', unsafe_allow_html=True)

# Input form
with st.form(key='chat_form', clear_on_submit=True):
    user_input = st.text_area("ğŸ’¬ ØµÙ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ø§Ù„ØªÙŠ ØªØ´Ø¹Ø± Ø¨Ù‡Ø§...", 
                             key='input', 
                             value="",
                             placeholder="Ù…Ø«Ø§Ù„: Ø£Ø¹Ø§Ù†ÙŠ Ù…Ù† Ø­Ø±Ø§Ø±Ø© ÙˆØ³Ø¹Ø§Ù„ Ù…Ù†Ø° ÙŠÙˆÙ…ÙŠÙ†")
    
    col1, col2 = st.columns([1, 1])
    with col1:
        analyze_btn = st.form_submit_button("ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ ğŸ©º")
    with col2:
        chat_btn = st.form_submit_button("Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ù„Ø© ğŸ’¬")
    
    if analyze_btn and user_input:
        with st.spinner("ğŸ” Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶..."):
            diagnosis = predict_medical_condition(user_input)
            st.session_state.diagnosis = diagnosis
            
            bot_response = get_medical_response(user_input, diagnosis)
            st.session_state.past.append(user_input)
            st.session_state.generated.append(bot_response)
            st.rerun()
    
    if chat_btn and user_input:
        st.session_state.past.append(user_input)
        with st.spinner("ğŸ¤– Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø±Ø¯..."):
            if st.session_state.diagnosis:
                bot_response = get_medical_response(user_input, st.session_state.diagnosis)
            else:
                bot_response = "Ù…Ù† ÙØ¶Ù„Ùƒ Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ 'ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶' Ø£ÙˆÙ„Ø§Ù‹ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ´Ø®ÙŠØµ Ø£ÙˆÙ„ÙŠ"
            
            st.session_state.generated.append(bot_response)
            st.rerun()
